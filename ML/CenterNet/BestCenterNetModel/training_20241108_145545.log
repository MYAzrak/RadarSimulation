2024-11-08 14:55:45,822 - INFO - Using device: cuda
2024-11-08 14:55:46,227 - INFO - Original dataset size - Train: 273, Validation: 69
2024-11-08 14:55:46,227 - INFO - Augmented training dataset size: 1638
2024-11-08 14:55:46,330 - INFO - Initial learning rate: 0.0001
2024-11-08 14:55:46,330 - INFO - Learning rate schedule - Factor: 0.5, Patience: 5, Min LR: 1e-07, Threshold: 0.0001
2024-11-08 14:55:55,128 - INFO - Epoch 1/500, Batch 0/205, Loss: 843.9820
2024-11-08 14:56:01,816 - INFO - Epoch 1/500, Batch 10/205, Loss: 446.6454
2024-11-08 14:56:08,611 - INFO - Epoch 1/500, Batch 20/205, Loss: 75.9804
2024-11-08 14:56:15,377 - INFO - Epoch 1/500, Batch 30/205, Loss: 5.9118
2024-11-08 14:56:21,799 - INFO - Epoch 1/500, Batch 40/205, Loss: 3.5184
2024-11-08 14:56:28,361 - INFO - Epoch 1/500, Batch 50/205, Loss: 3.3309
2024-11-08 14:56:35,002 - INFO - Epoch 1/500, Batch 60/205, Loss: 3.1435
2024-11-08 14:56:41,502 - INFO - Epoch 1/500, Batch 70/205, Loss: 2.8519
2024-11-08 14:56:48,205 - INFO - Epoch 1/500, Batch 80/205, Loss: 2.6576
2024-11-08 14:56:54,955 - INFO - Epoch 1/500, Batch 90/205, Loss: 2.6545
2024-11-08 14:57:01,627 - INFO - Epoch 1/500, Batch 100/205, Loss: 2.8148
2024-11-08 14:57:08,205 - INFO - Epoch 1/500, Batch 110/205, Loss: 2.4354
2024-11-08 14:57:14,830 - INFO - Epoch 1/500, Batch 120/205, Loss: 2.6353
2024-11-08 14:57:21,580 - INFO - Epoch 1/500, Batch 130/205, Loss: 2.5086
2024-11-08 14:57:28,455 - INFO - Epoch 1/500, Batch 140/205, Loss: 2.4925
2024-11-08 14:57:35,486 - INFO - Epoch 1/500, Batch 150/205, Loss: 2.3583
2024-11-08 14:57:42,377 - INFO - Epoch 1/500, Batch 160/205, Loss: 2.1667
2024-11-08 14:57:49,267 - INFO - Epoch 1/500, Batch 170/205, Loss: 2.3513
2024-11-08 14:57:56,267 - INFO - Epoch 1/500, Batch 180/205, Loss: 2.2320
2024-11-08 14:58:02,939 - INFO - Epoch 1/500, Batch 190/205, Loss: 2.3553
2024-11-08 14:58:09,502 - INFO - Epoch 1/500, Batch 200/205, Loss: 2.1855
2024-11-08 14:58:25,736 - INFO - Epoch 1/500, Training Loss: 43.9805, Validation Loss: 2.2656, LR: 0.000100
2024-11-08 14:58:25,752 - INFO - Saved new best model with validation loss: 2.2656
2024-11-08 14:58:33,162 - INFO - Epoch 2/500, Batch 0/205, Loss: 2.0012
2024-11-08 14:58:39,865 - INFO - Epoch 2/500, Batch 10/205, Loss: 2.2646
2024-11-08 14:58:46,568 - INFO - Epoch 2/500, Batch 20/205, Loss: 2.1640
2024-11-08 14:58:53,240 - INFO - Epoch 2/500, Batch 30/205, Loss: 2.0689
2024-11-08 14:58:59,881 - INFO - Epoch 2/500, Batch 40/205, Loss: 2.0828
2024-11-08 14:59:06,665 - INFO - Epoch 2/500, Batch 50/205, Loss: 2.2996
2024-11-08 14:59:13,540 - INFO - Epoch 2/500, Batch 60/205, Loss: 2.2877
2024-11-08 14:59:20,227 - INFO - Epoch 2/500, Batch 70/205, Loss: 2.0765
2024-11-08 14:59:26,774 - INFO - Epoch 2/500, Batch 80/205, Loss: 2.4296
2024-11-08 14:59:33,477 - INFO - Epoch 2/500, Batch 90/205, Loss: 1.9519
2024-11-08 14:59:40,259 - INFO - Epoch 2/500, Batch 100/205, Loss: 2.3907
2024-11-08 14:59:46,899 - INFO - Epoch 2/500, Batch 110/205, Loss: 2.0398
2024-11-08 14:59:53,634 - INFO - Epoch 2/500, Batch 120/205, Loss: 2.2504
2024-11-08 15:00:00,165 - INFO - Epoch 2/500, Batch 130/205, Loss: 2.0120
2024-11-08 15:00:06,884 - INFO - Epoch 2/500, Batch 140/205, Loss: 1.9632
2024-11-08 15:00:13,509 - INFO - Epoch 2/500, Batch 150/205, Loss: 2.0980
2024-11-08 15:00:20,149 - INFO - Epoch 2/500, Batch 160/205, Loss: 1.8799
2024-11-08 15:00:26,899 - INFO - Epoch 2/500, Batch 170/205, Loss: 2.2568
2024-11-08 15:00:33,384 - INFO - Epoch 2/500, Batch 180/205, Loss: 1.9498
2024-11-08 15:00:40,056 - INFO - Epoch 2/500, Batch 190/205, Loss: 1.9424
2024-11-08 15:00:46,806 - INFO - Epoch 2/500, Batch 200/205, Loss: 1.8585
2024-11-08 15:01:01,790 - INFO - Epoch 2/500, Training Loss: 2.0548, Validation Loss: 1.9583, LR: 0.000100
2024-11-08 15:01:01,806 - INFO - Saved new best model with validation loss: 1.9583
2024-11-08 15:01:09,054 - INFO - Epoch 3/500, Batch 0/205, Loss: 1.8409
2024-11-08 15:01:15,710 - INFO - Epoch 3/500, Batch 10/205, Loss: 1.9531
2024-11-08 15:01:22,413 - INFO - Epoch 3/500, Batch 20/205, Loss: 2.0401
2024-11-08 15:01:29,147 - INFO - Epoch 3/500, Batch 30/205, Loss: 1.7812
2024-11-08 15:01:35,835 - INFO - Epoch 3/500, Batch 40/205, Loss: 1.9200
2024-11-08 15:01:42,600 - INFO - Epoch 3/500, Batch 50/205, Loss: 1.9420
2024-11-08 15:01:49,194 - INFO - Epoch 3/500, Batch 60/205, Loss: 1.7264
2024-11-08 15:01:56,007 - INFO - Epoch 3/500, Batch 70/205, Loss: 1.8909
2024-11-08 15:02:02,694 - INFO - Epoch 3/500, Batch 80/205, Loss: 1.7534
2024-11-08 15:02:09,464 - INFO - Epoch 3/500, Batch 90/205, Loss: 1.8533
2024-11-08 15:02:16,136 - INFO - Epoch 3/500, Batch 100/205, Loss: 1.7645
2024-11-08 15:02:22,761 - INFO - Epoch 3/500, Batch 110/205, Loss: 1.8490
2024-11-08 15:02:29,761 - INFO - Epoch 3/500, Batch 120/205, Loss: 1.9312
2024-11-08 15:02:36,745 - INFO - Epoch 3/500, Batch 130/205, Loss: 1.7700
2024-11-08 15:02:43,901 - INFO - Epoch 3/500, Batch 140/205, Loss: 1.7934
2024-11-08 15:02:50,620 - INFO - Epoch 3/500, Batch 150/205, Loss: 1.9817
2024-11-08 15:02:57,339 - INFO - Epoch 3/500, Batch 160/205, Loss: 1.7209
2024-11-08 15:03:04,136 - INFO - Epoch 3/500, Batch 170/205, Loss: 1.8645
2024-11-08 15:03:10,839 - INFO - Epoch 3/500, Batch 180/205, Loss: 1.4527
2024-11-08 15:03:17,526 - INFO - Epoch 3/500, Batch 190/205, Loss: 1.8073
2024-11-08 15:03:24,198 - INFO - Epoch 3/500, Batch 200/205, Loss: 1.8108
2024-11-08 15:03:39,261 - INFO - Epoch 3/500, Training Loss: 1.8279, Validation Loss: 1.7617, LR: 0.000100
2024-11-08 15:03:39,276 - INFO - Saved new best model with validation loss: 1.7617
2024-11-08 15:03:46,565 - INFO - Epoch 4/500, Batch 0/205, Loss: 1.6955
2024-11-08 15:03:53,206 - INFO - Epoch 4/500, Batch 10/205, Loss: 1.6847
2024-11-08 15:03:59,878 - INFO - Epoch 4/500, Batch 20/205, Loss: 1.9585
2024-11-08 15:04:06,565 - INFO - Epoch 4/500, Batch 30/205, Loss: 1.8856
2024-11-08 15:04:13,284 - INFO - Epoch 4/500, Batch 40/205, Loss: 1.6447
2024-11-08 15:04:19,956 - INFO - Epoch 4/500, Batch 50/205, Loss: 1.9011
2024-11-08 15:04:26,768 - INFO - Epoch 4/500, Batch 60/205, Loss: 1.6556
2024-11-08 15:04:33,362 - INFO - Epoch 4/500, Batch 70/205, Loss: 1.7640
2024-11-08 15:04:40,128 - INFO - Epoch 4/500, Batch 80/205, Loss: 1.9760
2024-11-08 15:04:46,721 - INFO - Epoch 4/500, Batch 90/205, Loss: 1.6957
2024-11-08 15:04:53,518 - INFO - Epoch 4/500, Batch 100/205, Loss: 1.5493
2024-11-08 15:05:00,096 - INFO - Epoch 4/500, Batch 110/205, Loss: 1.7191
2024-11-08 15:05:06,784 - INFO - Epoch 4/500, Batch 120/205, Loss: 1.3979
2024-11-08 15:05:13,748 - INFO - Epoch 4/500, Batch 130/205, Loss: 1.7458
2024-11-08 15:05:20,451 - INFO - Epoch 4/500, Batch 140/205, Loss: 1.7291
2024-11-08 15:05:27,092 - INFO - Epoch 4/500, Batch 150/205, Loss: 1.7783
2024-11-08 15:05:33,639 - INFO - Epoch 4/500, Batch 160/205, Loss: 1.4273
2024-11-08 15:05:40,342 - INFO - Epoch 4/500, Batch 170/205, Loss: 1.6286
2024-11-08 15:05:47,076 - INFO - Epoch 4/500, Batch 180/205, Loss: 1.8239
2024-11-08 15:05:53,811 - INFO - Epoch 4/500, Batch 190/205, Loss: 1.5222
2024-11-08 15:06:00,686 - INFO - Epoch 4/500, Batch 200/205, Loss: 1.4637
2024-11-08 15:06:15,592 - INFO - Epoch 4/500, Training Loss: 1.6594, Validation Loss: 1.6232, LR: 0.000100
2024-11-08 15:06:15,623 - INFO - Saved new best model with validation loss: 1.6232
2024-11-08 15:06:22,905 - INFO - Epoch 5/500, Batch 0/205, Loss: 1.5277
2024-11-08 15:06:29,467 - INFO - Epoch 5/500, Batch 10/205, Loss: 1.5097
2024-11-08 15:06:36,139 - INFO - Epoch 5/500, Batch 20/205, Loss: 1.5097
2024-11-08 15:06:42,858 - INFO - Epoch 5/500, Batch 30/205, Loss: 1.8592
2024-11-08 15:06:49,530 - INFO - Epoch 5/500, Batch 40/205, Loss: 1.4325
2024-11-08 15:06:56,202 - INFO - Epoch 5/500, Batch 50/205, Loss: 1.5816
2024-11-08 15:07:02,795 - INFO - Epoch 5/500, Batch 60/205, Loss: 1.5503
2024-11-08 15:07:09,405 - INFO - Epoch 5/500, Batch 70/205, Loss: 1.4645
2024-11-08 15:07:15,999 - INFO - Epoch 5/500, Batch 80/205, Loss: 1.7520
2024-11-08 15:07:22,624 - INFO - Epoch 5/500, Batch 90/205, Loss: 1.5280
2024-11-08 15:07:29,358 - INFO - Epoch 5/500, Batch 100/205, Loss: 1.6723
2024-11-08 15:07:35,827 - INFO - Epoch 5/500, Batch 110/205, Loss: 1.6072
2024-11-08 15:07:42,452 - INFO - Epoch 5/500, Batch 120/205, Loss: 1.5925
2024-11-08 15:07:49,170 - INFO - Epoch 5/500, Batch 130/205, Loss: 1.4699
2024-11-08 15:07:55,702 - INFO - Epoch 5/500, Batch 140/205, Loss: 1.6138
2024-11-08 15:08:02,374 - INFO - Epoch 5/500, Batch 150/205, Loss: 1.3270
2024-11-08 15:08:09,045 - INFO - Epoch 5/500, Batch 160/205, Loss: 1.6890
2024-11-08 15:08:15,731 - INFO - Epoch 5/500, Batch 170/205, Loss: 1.4756
2024-11-08 15:08:22,418 - INFO - Epoch 5/500, Batch 180/205, Loss: 1.5566
2024-11-08 15:08:28,871 - INFO - Epoch 5/500, Batch 190/205, Loss: 1.4063
2024-11-08 15:08:35,637 - INFO - Epoch 5/500, Batch 200/205, Loss: 1.5432
2024-11-08 15:09:07,153 - INFO - Evaluation metrics - Precision: 0.437, Recall: 0.400, F1: 0.418
2024-11-08 15:09:11,621 - INFO - Saved visualization to plots/predictions_20241108_150909.png
2024-11-08 15:09:11,621 - INFO - Epoch 5/500, Training Loss: 1.5364, Validation Loss: 1.5194, LR: 0.000100
2024-11-08 15:09:11,637 - INFO - Saved new best model with validation loss: 1.5194
2024-11-08 15:09:18,825 - INFO - Epoch 6/500, Batch 0/205, Loss: 1.5114
2024-11-08 15:09:25,482 - INFO - Epoch 6/500, Batch 10/205, Loss: 1.4009
2024-11-08 15:09:32,185 - INFO - Epoch 6/500, Batch 20/205, Loss: 1.4549
2024-11-08 15:09:38,654 - INFO - Epoch 6/500, Batch 30/205, Loss: 1.5993
2024-11-08 15:09:45,263 - INFO - Epoch 6/500, Batch 40/205, Loss: 1.3759
2024-11-08 15:09:51,825 - INFO - Epoch 6/500, Batch 50/205, Loss: 1.3749
2024-11-08 15:09:58,529 - INFO - Epoch 6/500, Batch 60/205, Loss: 1.5019
2024-11-08 15:10:05,154 - INFO - Epoch 6/500, Batch 70/205, Loss: 1.4868
2024-11-08 15:10:11,716 - INFO - Epoch 6/500, Batch 80/205, Loss: 1.5549
2024-11-08 15:10:18,154 - INFO - Epoch 6/500, Batch 90/205, Loss: 1.3261
2024-11-08 15:10:24,950 - INFO - Epoch 6/500, Batch 100/205, Loss: 1.4733
2024-11-08 15:10:32,607 - INFO - Epoch 6/500, Batch 110/205, Loss: 1.7505
2024-11-08 15:10:39,176 - INFO - Epoch 6/500, Batch 120/205, Loss: 1.2342
2024-11-08 15:10:45,753 - INFO - Epoch 6/500, Batch 130/205, Loss: 1.4036
2024-11-08 15:10:53,348 - INFO - Epoch 6/500, Batch 140/205, Loss: 1.3198
2024-11-08 15:11:00,834 - INFO - Epoch 6/500, Batch 150/205, Loss: 1.2379
2024-11-08 15:11:07,681 - INFO - Epoch 6/500, Batch 160/205, Loss: 1.7416
2024-11-08 15:11:15,043 - INFO - Epoch 6/500, Batch 170/205, Loss: 1.5523
2024-11-08 15:11:22,533 - INFO - Epoch 6/500, Batch 180/205, Loss: 1.4335
2024-11-08 15:11:29,360 - INFO - Epoch 6/500, Batch 190/205, Loss: 1.3205
2024-11-08 15:11:36,666 - INFO - Epoch 6/500, Batch 200/205, Loss: 1.5474
2024-11-08 15:11:51,690 - INFO - Epoch 6/500, Training Loss: 1.4470, Validation Loss: 1.4649, LR: 0.000100
2024-11-08 15:11:51,721 - INFO - Saved new best model with validation loss: 1.4649
2024-11-08 15:11:59,016 - INFO - Epoch 7/500, Batch 0/205, Loss: 1.3291
2024-11-08 15:12:05,782 - INFO - Epoch 7/500, Batch 10/205, Loss: 1.4843
2024-11-08 15:12:12,532 - INFO - Epoch 7/500, Batch 20/205, Loss: 1.3391
2024-11-08 15:12:19,141 - INFO - Epoch 7/500, Batch 30/205, Loss: 1.6376
2024-11-08 15:12:25,985 - INFO - Epoch 7/500, Batch 40/205, Loss: 1.3286
2024-11-08 15:12:32,626 - INFO - Epoch 7/500, Batch 50/205, Loss: 1.4194
2024-11-08 15:12:39,360 - INFO - Epoch 7/500, Batch 60/205, Loss: 1.3732
2024-11-08 15:12:46,063 - INFO - Epoch 7/500, Batch 70/205, Loss: 1.2634
2024-11-08 15:12:52,735 - INFO - Epoch 7/500, Batch 80/205, Loss: 1.5749
2024-11-08 15:12:59,235 - INFO - Epoch 7/500, Batch 90/205, Loss: 1.2958
2024-11-08 15:13:05,860 - INFO - Epoch 7/500, Batch 100/205, Loss: 1.3345
2024-11-08 15:13:12,282 - INFO - Epoch 7/500, Batch 110/205, Loss: 1.3803
2024-11-08 15:13:18,829 - INFO - Epoch 7/500, Batch 120/205, Loss: 1.4561
2024-11-08 15:13:25,391 - INFO - Epoch 7/500, Batch 130/205, Loss: 1.5006
2024-11-08 15:13:32,042 - INFO - Epoch 7/500, Batch 140/205, Loss: 1.2490
2024-11-08 15:13:38,823 - INFO - Epoch 7/500, Batch 150/205, Loss: 1.3427
2024-11-08 15:13:45,464 - INFO - Epoch 7/500, Batch 160/205, Loss: 1.3997
2024-11-08 15:13:52,182 - INFO - Epoch 7/500, Batch 170/205, Loss: 1.4050
2024-11-08 15:13:58,667 - INFO - Epoch 7/500, Batch 180/205, Loss: 1.3404
2024-11-08 15:14:05,120 - INFO - Epoch 7/500, Batch 190/205, Loss: 1.2394
2024-11-08 15:14:11,620 - INFO - Epoch 7/500, Batch 200/205, Loss: 1.4071
2024-11-08 15:14:27,179 - INFO - Epoch 7/500, Training Loss: 1.3658, Validation Loss: 1.3619, LR: 0.000100
2024-11-08 15:14:27,194 - INFO - Saved new best model with validation loss: 1.3619
2024-11-08 15:14:34,473 - INFO - Epoch 8/500, Batch 0/205, Loss: 1.2878
2024-11-08 15:14:41,098 - INFO - Epoch 8/500, Batch 10/205, Loss: 1.3268
2024-11-08 15:14:47,817 - INFO - Epoch 8/500, Batch 20/205, Loss: 1.4043
2024-11-08 15:14:54,567 - INFO - Epoch 8/500, Batch 30/205, Loss: 1.4983
2024-11-08 15:15:01,177 - INFO - Epoch 8/500, Batch 40/205, Loss: 1.2152
2024-11-08 15:15:07,927 - INFO - Epoch 8/500, Batch 50/205, Loss: 1.2450
2024-11-08 15:15:14,489 - INFO - Epoch 8/500, Batch 60/205, Loss: 1.6368
2024-11-08 15:15:21,255 - INFO - Epoch 8/500, Batch 70/205, Loss: 1.3000
2024-11-08 15:15:27,786 - INFO - Epoch 8/500, Batch 80/205, Loss: 1.3105
2024-11-08 15:15:34,442 - INFO - Epoch 8/500, Batch 90/205, Loss: 1.4090
2024-11-08 15:15:41,083 - INFO - Epoch 8/500, Batch 100/205, Loss: 1.2961
2024-11-08 15:15:47,755 - INFO - Epoch 8/500, Batch 110/205, Loss: 1.1328
2024-11-08 15:15:54,380 - INFO - Epoch 8/500, Batch 120/205, Loss: 1.0507
2024-11-08 15:16:01,224 - INFO - Epoch 8/500, Batch 130/205, Loss: 1.2429
2024-11-08 15:16:07,958 - INFO - Epoch 8/500, Batch 140/205, Loss: 1.1797
2024-11-08 15:16:14,505 - INFO - Epoch 8/500, Batch 150/205, Loss: 1.4120
2024-11-08 15:16:21,224 - INFO - Epoch 8/500, Batch 160/205, Loss: 1.4146
2024-11-08 15:16:27,755 - INFO - Epoch 8/500, Batch 170/205, Loss: 1.2090
2024-11-08 15:16:34,411 - INFO - Epoch 8/500, Batch 180/205, Loss: 1.3776
2024-11-08 15:16:41,036 - INFO - Epoch 8/500, Batch 190/205, Loss: 1.3719
2024-11-08 15:16:47,661 - INFO - Epoch 8/500, Batch 200/205, Loss: 1.4745
2024-11-08 15:17:02,614 - INFO - Epoch 8/500, Training Loss: 1.2947, Validation Loss: 1.3283, LR: 0.000100
2024-11-08 15:17:02,645 - INFO - Saved new best model with validation loss: 1.3283
2024-11-08 15:17:09,884 - INFO - Epoch 9/500, Batch 0/205, Loss: 1.2355
2024-11-08 15:17:16,571 - INFO - Epoch 9/500, Batch 10/205, Loss: 1.3992
2024-11-08 15:17:23,379 - INFO - Epoch 9/500, Batch 20/205, Loss: 1.1534
2024-11-08 15:17:29,847 - INFO - Epoch 9/500, Batch 30/205, Loss: 1.3216
2024-11-08 15:17:36,457 - INFO - Epoch 9/500, Batch 40/205, Loss: 1.1543
2024-11-08 15:17:43,019 - INFO - Epoch 9/500, Batch 50/205, Loss: 1.4739
2024-11-08 15:17:49,613 - INFO - Epoch 9/500, Batch 60/205, Loss: 1.1584
2024-11-08 15:17:56,301 - INFO - Epoch 9/500, Batch 70/205, Loss: 1.3855
2024-11-08 15:18:02,910 - INFO - Epoch 9/500, Batch 80/205, Loss: 1.1032
2024-11-08 15:18:09,316 - INFO - Epoch 9/500, Batch 90/205, Loss: 1.2167
2024-11-08 15:18:15,988 - INFO - Epoch 9/500, Batch 100/205, Loss: 1.1338
2024-11-08 15:18:22,441 - INFO - Epoch 9/500, Batch 110/205, Loss: 1.2869
2024-11-08 15:18:29,051 - INFO - Epoch 9/500, Batch 120/205, Loss: 1.1424
2024-11-08 15:18:35,519 - INFO - Epoch 9/500, Batch 130/205, Loss: 1.2074
2024-11-08 15:18:42,082 - INFO - Epoch 9/500, Batch 140/205, Loss: 1.1832
2024-11-08 15:18:48,816 - INFO - Epoch 9/500, Batch 150/205, Loss: 1.0625
2024-11-08 15:18:55,285 - INFO - Epoch 9/500, Batch 160/205, Loss: 1.2979
2024-11-08 15:19:02,019 - INFO - Epoch 9/500, Batch 170/205, Loss: 1.1588
2024-11-08 15:19:08,535 - INFO - Epoch 9/500, Batch 180/205, Loss: 1.1088
2024-11-08 15:19:15,097 - INFO - Epoch 9/500, Batch 190/205, Loss: 1.2414
2024-11-08 15:19:21,582 - INFO - Epoch 9/500, Batch 200/205, Loss: 1.0780
2024-11-08 15:19:36,394 - INFO - Epoch 9/500, Training Loss: 1.2269, Validation Loss: 1.2756, LR: 0.000100
2024-11-08 15:19:36,426 - INFO - Saved new best model with validation loss: 1.2756
2024-11-08 15:19:43,564 - INFO - Epoch 10/500, Batch 0/205, Loss: 1.2974
2024-11-08 15:19:50,376 - INFO - Epoch 10/500, Batch 10/205, Loss: 1.0057
2024-11-08 15:19:56,986 - INFO - Epoch 10/500, Batch 20/205, Loss: 1.2387
2024-11-08 15:20:03,705 - INFO - Epoch 10/500, Batch 30/205, Loss: 1.0636
2024-11-08 15:20:10,408 - INFO - Epoch 10/500, Batch 40/205, Loss: 1.1864
2024-11-08 15:20:17,236 - INFO - Epoch 10/500, Batch 50/205, Loss: 1.1133
2024-11-08 15:20:24,201 - INFO - Epoch 10/500, Batch 60/205, Loss: 1.1590
2024-11-08 15:20:30,701 - INFO - Epoch 10/500, Batch 70/205, Loss: 1.0743
2024-11-08 15:20:37,373 - INFO - Epoch 10/500, Batch 80/205, Loss: 1.2177
2024-11-08 15:20:43,904 - INFO - Epoch 10/500, Batch 90/205, Loss: 1.2417
2024-11-08 15:20:50,529 - INFO - Epoch 10/500, Batch 100/205, Loss: 1.0836
2024-11-08 15:20:57,185 - INFO - Epoch 10/500, Batch 110/205, Loss: 1.2391
2024-11-08 15:21:03,998 - INFO - Epoch 10/500, Batch 120/205, Loss: 1.1559
2024-11-08 15:21:10,451 - INFO - Epoch 10/500, Batch 130/205, Loss: 1.1058
2024-11-08 15:21:17,263 - INFO - Epoch 10/500, Batch 140/205, Loss: 1.2009
2024-11-08 15:21:23,857 - INFO - Epoch 10/500, Batch 150/205, Loss: 1.1337
2024-11-08 15:21:30,529 - INFO - Epoch 10/500, Batch 160/205, Loss: 1.1696
2024-11-08 15:21:37,216 - INFO - Epoch 10/500, Batch 170/205, Loss: 1.1058
2024-11-08 15:21:43,841 - INFO - Epoch 10/500, Batch 180/205, Loss: 1.2219
2024-11-08 15:21:50,513 - INFO - Epoch 10/500, Batch 190/205, Loss: 1.0650
2024-11-08 15:21:57,138 - INFO - Epoch 10/500, Batch 200/205, Loss: 1.1217
2024-11-08 15:22:28,326 - INFO - Evaluation metrics - Precision: 0.583, Recall: 0.684, F1: 0.630
2024-11-08 15:22:32,482 - INFO - Saved visualization to plots/predictions_20241108_152230.png
2024-11-08 15:22:32,482 - INFO - Epoch 10/500, Training Loss: 1.1575, Validation Loss: 1.2025, LR: 0.000100
2024-11-08 15:22:32,498 - INFO - Saved new best model with validation loss: 1.2025
2024-11-08 15:22:39,830 - INFO - Epoch 11/500, Batch 0/205, Loss: 1.0479
2024-11-08 15:22:46,330 - INFO - Epoch 11/500, Batch 10/205, Loss: 1.1697
2024-11-08 15:22:52,924 - INFO - Epoch 11/500, Batch 20/205, Loss: 1.0203
2024-11-08 15:22:59,596 - INFO - Epoch 11/500, Batch 30/205, Loss: 1.4697
2024-11-08 15:23:06,159 - INFO - Epoch 11/500, Batch 40/205, Loss: 1.3000
2024-11-08 15:23:12,893 - INFO - Epoch 11/500, Batch 50/205, Loss: 1.1063
2024-11-08 15:23:19,518 - INFO - Epoch 11/500, Batch 60/205, Loss: 1.0177
2024-11-08 15:23:26,107 - INFO - Epoch 11/500, Batch 70/205, Loss: 1.3578
2024-11-08 15:23:32,732 - INFO - Epoch 11/500, Batch 80/205, Loss: 0.9472
2024-11-08 15:23:39,373 - INFO - Epoch 11/500, Batch 90/205, Loss: 1.1258
2024-11-08 15:23:45,966 - INFO - Epoch 11/500, Batch 100/205, Loss: 1.2371
2024-11-08 15:23:52,544 - INFO - Epoch 11/500, Batch 110/205, Loss: 1.1067
2024-11-08 15:23:59,060 - INFO - Epoch 11/500, Batch 120/205, Loss: 1.2591
2024-11-08 15:24:05,623 - INFO - Epoch 11/500, Batch 130/205, Loss: 1.2402
2024-11-08 15:24:12,248 - INFO - Epoch 11/500, Batch 140/205, Loss: 1.2049
2024-11-08 15:24:18,904 - INFO - Epoch 11/500, Batch 150/205, Loss: 1.1201
2024-11-08 15:24:25,623 - INFO - Epoch 11/500, Batch 160/205, Loss: 0.9875
2024-11-08 15:24:32,076 - INFO - Epoch 11/500, Batch 170/205, Loss: 1.0226
2024-11-08 15:24:38,591 - INFO - Epoch 11/500, Batch 180/205, Loss: 0.8697
2024-11-08 15:24:45,216 - INFO - Epoch 11/500, Batch 190/205, Loss: 1.1618
2024-11-08 15:24:51,794 - INFO - Epoch 11/500, Batch 200/205, Loss: 1.0588
2024-11-08 15:25:06,482 - INFO - Epoch 11/500, Training Loss: 1.0966, Validation Loss: 1.1920, LR: 0.000100
2024-11-08 15:25:06,498 - INFO - Saved new best model with validation loss: 1.1920
2024-11-08 15:25:13,659 - INFO - Epoch 12/500, Batch 0/205, Loss: 1.1052
2024-11-08 15:25:20,315 - INFO - Epoch 12/500, Batch 10/205, Loss: 1.0372
2024-11-08 15:25:27,018 - INFO - Epoch 12/500, Batch 20/205, Loss: 0.9992
2024-11-08 15:25:33,581 - INFO - Epoch 12/500, Batch 30/205, Loss: 0.9975
2024-11-08 15:25:40,143 - INFO - Epoch 12/500, Batch 40/205, Loss: 1.0412
2024-11-08 15:25:46,565 - INFO - Epoch 12/500, Batch 50/205, Loss: 1.0722
2024-11-08 15:25:53,127 - INFO - Epoch 12/500, Batch 60/205, Loss: 1.0081
2024-11-08 15:25:59,752 - INFO - Epoch 12/500, Batch 70/205, Loss: 1.1194
2024-11-08 15:26:06,315 - INFO - Epoch 12/500, Batch 80/205, Loss: 0.8149
2024-11-08 15:26:12,956 - INFO - Epoch 12/500, Batch 90/205, Loss: 0.9722
2024-11-08 15:26:19,377 - INFO - Epoch 12/500, Batch 100/205, Loss: 0.8791
2024-11-08 15:26:25,924 - INFO - Epoch 12/500, Batch 110/205, Loss: 0.9769
2024-11-08 15:26:32,538 - INFO - Epoch 12/500, Batch 120/205, Loss: 1.2031
2024-11-08 15:26:39,226 - INFO - Epoch 12/500, Batch 130/205, Loss: 1.0719
2024-11-08 15:26:45,835 - INFO - Epoch 12/500, Batch 140/205, Loss: 1.0488
2024-11-08 15:26:52,413 - INFO - Epoch 12/500, Batch 150/205, Loss: 1.1670
2024-11-08 15:26:58,882 - INFO - Epoch 12/500, Batch 160/205, Loss: 1.1420
2024-11-08 15:27:05,523 - INFO - Epoch 12/500, Batch 170/205, Loss: 1.1777
2024-11-08 15:27:12,038 - INFO - Epoch 12/500, Batch 180/205, Loss: 0.8561
2024-11-08 15:27:18,538 - INFO - Epoch 12/500, Batch 190/205, Loss: 1.1629
2024-11-08 15:27:24,944 - INFO - Epoch 12/500, Batch 200/205, Loss: 0.9683
2024-11-08 15:27:39,898 - INFO - Epoch 12/500, Training Loss: 1.0381, Validation Loss: 1.1688, LR: 0.000100
2024-11-08 15:27:39,913 - INFO - Saved new best model with validation loss: 1.1688
2024-11-08 15:27:47,062 - INFO - Epoch 13/500, Batch 0/205, Loss: 1.0909
2024-11-08 15:27:53,687 - INFO - Epoch 13/500, Batch 10/205, Loss: 0.9068
2024-11-08 15:28:00,390 - INFO - Epoch 13/500, Batch 20/205, Loss: 0.8860
2024-11-08 15:28:06,874 - INFO - Epoch 13/500, Batch 30/205, Loss: 1.0964
2024-11-08 15:28:13,577 - INFO - Epoch 13/500, Batch 40/205, Loss: 1.1319
2024-11-08 15:28:20,062 - INFO - Epoch 13/500, Batch 50/205, Loss: 1.2956
2024-11-08 15:28:26,624 - INFO - Epoch 13/500, Batch 60/205, Loss: 0.9864
2024-11-08 15:28:33,390 - INFO - Epoch 13/500, Batch 70/205, Loss: 1.0050
2024-11-08 15:28:39,999 - INFO - Epoch 13/500, Batch 80/205, Loss: 0.9044
2024-11-08 15:28:46,593 - INFO - Epoch 13/500, Batch 90/205, Loss: 0.9247
2024-11-08 15:28:53,171 - INFO - Epoch 13/500, Batch 100/205, Loss: 1.1374
2024-11-08 15:28:59,639 - INFO - Epoch 13/500, Batch 110/205, Loss: 0.9305
2024-11-08 15:29:06,217 - INFO - Epoch 13/500, Batch 120/205, Loss: 1.1085
2024-11-08 15:29:12,780 - INFO - Epoch 13/500, Batch 130/205, Loss: 1.0939
2024-11-08 15:29:19,514 - INFO - Epoch 13/500, Batch 140/205, Loss: 0.9361
2024-11-08 15:29:26,139 - INFO - Epoch 13/500, Batch 150/205, Loss: 0.8196
2024-11-08 15:29:32,832 - INFO - Epoch 13/500, Batch 160/205, Loss: 0.9660
2024-11-08 15:29:39,379 - INFO - Epoch 13/500, Batch 170/205, Loss: 1.0194
2024-11-08 15:29:45,941 - INFO - Epoch 13/500, Batch 180/205, Loss: 0.9236
2024-11-08 15:29:52,457 - INFO - Epoch 13/500, Batch 190/205, Loss: 1.0780
2024-11-08 15:29:59,145 - INFO - Epoch 13/500, Batch 200/205, Loss: 1.0544
2024-11-08 15:30:14,316 - INFO - Epoch 13/500, Training Loss: 0.9823, Validation Loss: 1.1204, LR: 0.000100
2024-11-08 15:30:14,348 - INFO - Saved new best model with validation loss: 1.1204
2024-11-08 15:30:21,612 - INFO - Epoch 14/500, Batch 0/205, Loss: 1.1035
2024-11-08 15:30:28,237 - INFO - Epoch 14/500, Batch 10/205, Loss: 0.8515
2024-11-08 15:30:34,955 - INFO - Epoch 14/500, Batch 20/205, Loss: 1.0888
2024-11-08 15:30:41,487 - INFO - Epoch 14/500, Batch 30/205, Loss: 0.8536
2024-11-08 15:30:48,268 - INFO - Epoch 14/500, Batch 40/205, Loss: 0.8647
2024-11-08 15:30:54,955 - INFO - Epoch 14/500, Batch 50/205, Loss: 0.8213
2024-11-08 15:31:01,596 - INFO - Epoch 14/500, Batch 60/205, Loss: 0.8402
2024-11-08 15:31:08,221 - INFO - Epoch 14/500, Batch 70/205, Loss: 0.7783
2024-11-08 15:31:15,002 - INFO - Epoch 14/500, Batch 80/205, Loss: 1.0061
2024-11-08 15:31:21,518 - INFO - Epoch 14/500, Batch 90/205, Loss: 1.0319
2024-11-08 15:31:28,127 - INFO - Epoch 14/500, Batch 100/205, Loss: 0.9725
2024-11-08 15:31:34,737 - INFO - Epoch 14/500, Batch 110/205, Loss: 0.7830
2024-11-08 15:31:41,362 - INFO - Epoch 14/500, Batch 120/205, Loss: 0.8421
2024-11-08 15:31:48,018 - INFO - Epoch 14/500, Batch 130/205, Loss: 1.0537
2024-11-08 15:31:54,643 - INFO - Epoch 14/500, Batch 140/205, Loss: 0.9149
2024-11-08 15:32:01,284 - INFO - Epoch 14/500, Batch 150/205, Loss: 1.0485
2024-11-08 15:32:07,799 - INFO - Epoch 14/500, Batch 160/205, Loss: 0.9135
2024-11-08 15:32:14,518 - INFO - Epoch 14/500, Batch 170/205, Loss: 0.8241
2024-11-08 15:32:21,127 - INFO - Epoch 14/500, Batch 180/205, Loss: 1.0468
2024-11-08 15:32:27,737 - INFO - Epoch 14/500, Batch 190/205, Loss: 1.0685
2024-11-08 15:32:34,457 - INFO - Epoch 14/500, Batch 200/205, Loss: 0.7808
2024-11-08 15:32:49,457 - INFO - Epoch 14/500, Training Loss: 0.9293, Validation Loss: 1.1340, LR: 0.000100
2024-11-08 15:32:56,535 - INFO - Epoch 15/500, Batch 0/205, Loss: 1.1321
2024-11-08 15:33:03,191 - INFO - Epoch 15/500, Batch 10/205, Loss: 0.7747
2024-11-08 15:33:09,926 - INFO - Epoch 15/500, Batch 20/205, Loss: 0.9655
2024-11-08 15:33:16,535 - INFO - Epoch 15/500, Batch 30/205, Loss: 0.7635
2024-11-08 15:33:23,004 - INFO - Epoch 15/500, Batch 40/205, Loss: 1.2771
2024-11-08 15:33:29,551 - INFO - Epoch 15/500, Batch 50/205, Loss: 0.7385
2024-11-08 15:33:36,223 - INFO - Epoch 15/500, Batch 60/205, Loss: 1.0090
2024-11-08 15:33:43,066 - INFO - Epoch 15/500, Batch 70/205, Loss: 0.8817
2024-11-08 15:33:49,582 - INFO - Epoch 15/500, Batch 80/205, Loss: 0.6883
2024-11-08 15:33:56,176 - INFO - Epoch 15/500, Batch 90/205, Loss: 0.9603
2024-11-08 15:34:02,770 - INFO - Epoch 15/500, Batch 100/205, Loss: 0.6982
2024-11-08 15:34:09,363 - INFO - Epoch 15/500, Batch 110/205, Loss: 0.9429
2024-11-08 15:34:15,988 - INFO - Epoch 15/500, Batch 120/205, Loss: 0.8328
2024-11-08 15:34:22,410 - INFO - Epoch 15/500, Batch 130/205, Loss: 0.9397
2024-11-08 15:34:29,082 - INFO - Epoch 15/500, Batch 140/205, Loss: 0.9485
2024-11-08 15:34:35,676 - INFO - Epoch 15/500, Batch 150/205, Loss: 0.8364
2024-11-08 15:34:42,301 - INFO - Epoch 15/500, Batch 160/205, Loss: 0.9165
2024-11-08 15:34:48,910 - INFO - Epoch 15/500, Batch 170/205, Loss: 0.8169
2024-11-08 15:34:55,363 - INFO - Epoch 15/500, Batch 180/205, Loss: 0.9666
2024-11-08 15:35:02,004 - INFO - Epoch 15/500, Batch 190/205, Loss: 1.0170
2024-11-08 15:35:08,691 - INFO - Epoch 15/500, Batch 200/205, Loss: 0.9590
2024-11-08 15:35:40,102 - INFO - Evaluation metrics - Precision: 0.541, Recall: 0.767, F1: 0.634
2024-11-08 15:35:44,383 - INFO - Saved visualization to plots/predictions_20241108_153542.png
2024-11-08 15:35:44,383 - INFO - Epoch 15/500, Training Loss: 0.8810, Validation Loss: 1.1344, LR: 0.000100
2024-11-08 15:35:51,631 - INFO - Epoch 16/500, Batch 0/205, Loss: 0.9374
2024-11-08 15:35:58,459 - INFO - Epoch 16/500, Batch 10/205, Loss: 0.7188
2024-11-08 15:36:05,022 - INFO - Epoch 16/500, Batch 20/205, Loss: 0.7384
2024-11-08 15:36:11,631 - INFO - Epoch 16/500, Batch 30/205, Loss: 0.8352
2024-11-08 15:36:18,272 - INFO - Epoch 16/500, Batch 40/205, Loss: 0.8832
2024-11-08 15:36:24,850 - INFO - Epoch 16/500, Batch 50/205, Loss: 0.8256
2024-11-08 15:36:31,475 - INFO - Epoch 16/500, Batch 60/205, Loss: 0.8029
2024-11-08 15:36:38,162 - INFO - Epoch 16/500, Batch 70/205, Loss: 0.8248
2024-11-08 15:36:44,787 - INFO - Epoch 16/500, Batch 80/205, Loss: 0.8177
2024-11-08 15:36:51,381 - INFO - Epoch 16/500, Batch 90/205, Loss: 0.8504
2024-11-08 15:36:58,037 - INFO - Epoch 16/500, Batch 100/205, Loss: 0.7473
2024-11-08 15:37:04,631 - INFO - Epoch 16/500, Batch 110/205, Loss: 0.7221
2024-11-08 15:37:11,240 - INFO - Epoch 16/500, Batch 120/205, Loss: 0.8866
2024-11-08 15:37:17,865 - INFO - Epoch 16/500, Batch 130/205, Loss: 1.1020
2024-11-08 15:37:24,365 - INFO - Epoch 16/500, Batch 140/205, Loss: 1.0938
2024-11-08 15:37:31,131 - INFO - Epoch 16/500, Batch 150/205, Loss: 0.9517
2024-11-08 15:37:37,709 - INFO - Epoch 16/500, Batch 160/205, Loss: 0.7356
2024-11-08 15:37:44,303 - INFO - Epoch 16/500, Batch 170/205, Loss: 0.9621
2024-11-08 15:37:50,803 - INFO - Epoch 16/500, Batch 180/205, Loss: 0.7454
2024-11-08 15:37:57,506 - INFO - Epoch 16/500, Batch 190/205, Loss: 0.8922
2024-11-08 15:38:03,975 - INFO - Epoch 16/500, Batch 200/205, Loss: 0.9589
2024-11-08 15:38:18,928 - INFO - Epoch 16/500, Training Loss: 0.8385, Validation Loss: 1.2019, LR: 0.000100
2024-11-08 15:38:25,975 - INFO - Epoch 17/500, Batch 0/205, Loss: 0.9253
2024-11-08 15:38:32,647 - INFO - Epoch 17/500, Batch 10/205, Loss: 0.9757
2024-11-08 15:38:39,484 - INFO - Epoch 17/500, Batch 20/205, Loss: 0.8070
2024-11-08 15:38:46,094 - INFO - Epoch 17/500, Batch 30/205, Loss: 0.8818
2024-11-08 15:38:52,750 - INFO - Epoch 17/500, Batch 40/205, Loss: 0.8924
2024-11-08 15:38:59,469 - INFO - Epoch 17/500, Batch 50/205, Loss: 0.9311
2024-11-08 15:39:06,156 - INFO - Epoch 17/500, Batch 60/205, Loss: 0.7519
2024-11-08 15:39:12,703 - INFO - Epoch 17/500, Batch 70/205, Loss: 1.0262
2024-11-08 15:39:19,312 - INFO - Epoch 17/500, Batch 80/205, Loss: 0.7074
2024-11-08 15:39:25,937 - INFO - Epoch 17/500, Batch 90/205, Loss: 0.6348
2024-11-08 15:39:32,609 - INFO - Epoch 17/500, Batch 100/205, Loss: 0.7121
2024-11-08 15:39:39,219 - INFO - Epoch 17/500, Batch 110/205, Loss: 0.6545
2024-11-08 15:39:45,859 - INFO - Epoch 17/500, Batch 120/205, Loss: 0.7749
2024-11-08 15:39:52,484 - INFO - Epoch 17/500, Batch 130/205, Loss: 0.8532
2024-11-08 15:39:59,328 - INFO - Epoch 17/500, Batch 140/205, Loss: 0.6845
2024-11-08 15:40:06,031 - INFO - Epoch 17/500, Batch 150/205, Loss: 0.9498
2024-11-08 15:40:12,625 - INFO - Epoch 17/500, Batch 160/205, Loss: 0.9774
2024-11-08 15:40:19,297 - INFO - Epoch 17/500, Batch 170/205, Loss: 0.7685
2024-11-08 15:40:26,000 - INFO - Epoch 17/500, Batch 180/205, Loss: 0.7412
2024-11-08 15:40:32,797 - INFO - Epoch 17/500, Batch 190/205, Loss: 0.7303
2024-11-08 15:40:40,731 - INFO - Epoch 17/500, Batch 200/205, Loss: 0.7174
2024-11-08 15:40:56,477 - INFO - Epoch 17/500, Training Loss: 0.7869, Validation Loss: 1.1664, LR: 0.000100
2024-11-08 15:41:03,708 - INFO - Epoch 18/500, Batch 0/205, Loss: 0.9284
2024-11-08 15:41:10,411 - INFO - Epoch 18/500, Batch 10/205, Loss: 0.6902
2024-11-08 15:41:17,176 - INFO - Epoch 18/500, Batch 20/205, Loss: 0.7712
2024-11-08 15:41:23,801 - INFO - Epoch 18/500, Batch 30/205, Loss: 0.5810
2024-11-08 15:41:30,286 - INFO - Epoch 18/500, Batch 40/205, Loss: 0.9181
2024-11-08 15:41:36,926 - INFO - Epoch 18/500, Batch 50/205, Loss: 0.6632
2024-11-08 15:41:43,855 - INFO - Epoch 18/500, Batch 60/205, Loss: 0.5725
2024-11-08 15:41:50,371 - INFO - Epoch 18/500, Batch 70/205, Loss: 0.5849
2024-11-08 15:41:56,980 - INFO - Epoch 18/500, Batch 80/205, Loss: 0.6214
2024-11-08 15:42:03,652 - INFO - Epoch 18/500, Batch 90/205, Loss: 0.6308
2024-11-08 15:42:10,339 - INFO - Epoch 18/500, Batch 100/205, Loss: 0.6387
2024-11-08 15:42:16,886 - INFO - Epoch 18/500, Batch 110/205, Loss: 0.7973
2024-11-08 15:42:23,668 - INFO - Epoch 18/500, Batch 120/205, Loss: 0.6080
2024-11-08 15:42:30,339 - INFO - Epoch 18/500, Batch 130/205, Loss: 0.6385
2024-11-08 15:42:36,980 - INFO - Epoch 18/500, Batch 140/205, Loss: 0.7474
2024-11-08 15:42:43,574 - INFO - Epoch 18/500, Batch 150/205, Loss: 0.5840
2024-11-08 15:42:50,386 - INFO - Epoch 18/500, Batch 160/205, Loss: 0.8381
2024-11-08 15:42:57,027 - INFO - Epoch 18/500, Batch 170/205, Loss: 0.8156
2024-11-08 15:43:03,683 - INFO - Epoch 18/500, Batch 180/205, Loss: 0.8631
2024-11-08 15:43:10,261 - INFO - Epoch 18/500, Batch 190/205, Loss: 0.7934
2024-11-08 15:43:16,886 - INFO - Epoch 18/500, Batch 200/205, Loss: 0.7328
2024-11-08 15:43:32,199 - INFO - Epoch 18/500, Training Loss: 0.7473, Validation Loss: 1.1752, LR: 0.000100
2024-11-08 15:43:39,508 - INFO - Epoch 19/500, Batch 0/205, Loss: 0.6109
2024-11-08 15:43:46,227 - INFO - Epoch 19/500, Batch 10/205, Loss: 0.6263
2024-11-08 15:43:52,946 - INFO - Epoch 19/500, Batch 20/205, Loss: 0.6397
2024-11-08 15:43:59,665 - INFO - Epoch 19/500, Batch 30/205, Loss: 0.5728
2024-11-08 15:44:06,336 - INFO - Epoch 19/500, Batch 40/205, Loss: 0.6604
2024-11-08 15:44:12,899 - INFO - Epoch 19/500, Batch 50/205, Loss: 0.7678
2024-11-08 15:44:19,430 - INFO - Epoch 19/500, Batch 60/205, Loss: 0.7005
2024-11-08 15:44:26,024 - INFO - Epoch 19/500, Batch 70/205, Loss: 0.6918
2024-11-08 15:44:32,727 - INFO - Epoch 19/500, Batch 80/205, Loss: 0.8059
2024-11-08 15:44:39,274 - INFO - Epoch 19/500, Batch 90/205, Loss: 0.6950
2024-11-08 15:44:46,137 - INFO - Epoch 19/500, Batch 100/205, Loss: 0.5957
2024-11-08 15:44:52,778 - INFO - Epoch 19/500, Batch 110/205, Loss: 0.9411
2024-11-08 15:44:59,262 - INFO - Epoch 19/500, Batch 120/205, Loss: 0.7109
2024-11-08 15:45:05,966 - INFO - Epoch 19/500, Batch 130/205, Loss: 0.6738
2024-11-08 15:45:12,622 - INFO - Epoch 19/500, Batch 140/205, Loss: 0.7378
2024-11-08 15:45:19,419 - INFO - Epoch 19/500, Batch 150/205, Loss: 0.6279
2024-11-08 15:45:25,966 - INFO - Epoch 19/500, Batch 160/205, Loss: 0.5492
2024-11-08 15:45:32,747 - INFO - Epoch 19/500, Batch 170/205, Loss: 0.8765
2024-11-08 15:45:39,341 - INFO - Epoch 19/500, Batch 180/205, Loss: 0.5680
2024-11-08 15:45:45,825 - INFO - Epoch 19/500, Batch 190/205, Loss: 0.9717
2024-11-08 15:45:52,434 - INFO - Epoch 19/500, Batch 200/205, Loss: 0.7442
2024-11-08 15:46:07,450 - INFO - Learning rate decreased from 0.000100 to 0.000050
2024-11-08 15:46:07,450 - INFO - Epoch 19/500, Training Loss: 0.7031, Validation Loss: 1.1748, LR: 0.000050
2024-11-08 15:46:14,528 - INFO - Epoch 20/500, Batch 0/205, Loss: 0.6160
2024-11-08 15:46:21,122 - INFO - Epoch 20/500, Batch 10/205, Loss: 0.5913
2024-11-08 15:46:27,778 - INFO - Epoch 20/500, Batch 20/205, Loss: 0.6882
2024-11-08 15:46:34,403 - INFO - Epoch 20/500, Batch 30/205, Loss: 0.5487
2024-11-08 15:46:41,012 - INFO - Epoch 20/500, Batch 40/205, Loss: 0.7556
2024-11-08 15:46:47,591 - INFO - Epoch 20/500, Batch 50/205, Loss: 0.5286
2024-11-08 15:46:54,278 - INFO - Epoch 20/500, Batch 60/205, Loss: 0.6918
2024-11-08 15:47:00,762 - INFO - Epoch 20/500, Batch 70/205, Loss: 0.7142
2024-11-08 15:47:07,419 - INFO - Epoch 20/500, Batch 80/205, Loss: 0.7991
2024-11-08 15:47:14,028 - INFO - Epoch 20/500, Batch 90/205, Loss: 0.5810
2024-11-08 15:47:20,419 - INFO - Epoch 20/500, Batch 100/205, Loss: 0.5754
2024-11-08 15:47:27,075 - INFO - Epoch 20/500, Batch 110/205, Loss: 0.6491
2024-11-08 15:47:33,669 - INFO - Epoch 20/500, Batch 120/205, Loss: 0.6531
2024-11-08 15:47:40,169 - INFO - Epoch 20/500, Batch 130/205, Loss: 0.5509
2024-11-08 15:47:46,971 - INFO - Epoch 20/500, Batch 140/205, Loss: 0.7524
2024-11-08 15:47:53,440 - INFO - Epoch 20/500, Batch 150/205, Loss: 0.5675
2024-11-08 15:48:00,018 - INFO - Epoch 20/500, Batch 160/205, Loss: 0.7157
2024-11-08 15:48:06,736 - INFO - Epoch 20/500, Batch 170/205, Loss: 0.6235
2024-11-08 15:48:13,158 - INFO - Epoch 20/500, Batch 180/205, Loss: 0.6474
2024-11-08 15:48:19,783 - INFO - Epoch 20/500, Batch 190/205, Loss: 0.6568
2024-11-08 15:48:26,361 - INFO - Epoch 20/500, Batch 200/205, Loss: 0.8820
2024-11-08 15:48:57,518 - INFO - Evaluation metrics - Precision: 0.577, Recall: 0.783, F1: 0.665
2024-11-08 15:49:01,627 - INFO - Saved visualization to plots/predictions_20241108_154859.png
2024-11-08 15:49:01,627 - INFO - Epoch 20/500, Training Loss: 0.6421, Validation Loss: 1.1855, LR: 0.000050
2024-11-08 15:49:08,912 - INFO - Epoch 21/500, Batch 0/205, Loss: 0.5746
2024-11-08 15:49:15,397 - INFO - Epoch 21/500, Batch 10/205, Loss: 0.5435
2024-11-08 15:49:22,006 - INFO - Epoch 21/500, Batch 20/205, Loss: 0.4943
2024-11-08 15:49:28,584 - INFO - Epoch 21/500, Batch 30/205, Loss: 0.4770
2024-11-08 15:49:35,131 - INFO - Epoch 21/500, Batch 40/205, Loss: 0.5325
2024-11-08 15:49:41,850 - INFO - Epoch 21/500, Batch 50/205, Loss: 0.5845
2024-11-08 15:49:48,287 - INFO - Epoch 21/500, Batch 60/205, Loss: 0.5895
2024-11-08 15:49:54,897 - INFO - Epoch 21/500, Batch 70/205, Loss: 0.5428
2024-11-08 15:50:01,522 - INFO - Epoch 21/500, Batch 80/205, Loss: 0.5639
2024-11-08 15:50:08,193 - INFO - Epoch 21/500, Batch 90/205, Loss: 0.6964
2024-11-08 15:50:14,693 - INFO - Epoch 21/500, Batch 100/205, Loss: 0.6373
2024-11-08 15:50:22,497 - INFO - Epoch 21/500, Batch 110/205, Loss: 0.5789
2024-11-08 15:50:29,699 - INFO - Epoch 21/500, Batch 120/205, Loss: 0.9038
2024-11-08 15:50:36,813 - INFO - Epoch 21/500, Batch 130/205, Loss: 0.4415
2024-11-08 15:50:44,396 - INFO - Epoch 21/500, Batch 140/205, Loss: 0.7100
2024-11-08 15:50:52,970 - INFO - Epoch 21/500, Batch 150/205, Loss: 0.5308
2024-11-08 15:51:00,157 - INFO - Epoch 21/500, Batch 160/205, Loss: 0.6045
2024-11-08 15:51:07,757 - INFO - Epoch 21/500, Batch 170/205, Loss: 0.6163
2024-11-08 15:51:15,008 - INFO - Epoch 21/500, Batch 180/205, Loss: 0.9909
2024-11-08 15:51:22,340 - INFO - Epoch 21/500, Batch 190/205, Loss: 0.8096
2024-11-08 15:51:30,253 - INFO - Epoch 21/500, Batch 200/205, Loss: 0.5633
2024-11-08 15:51:47,312 - INFO - Epoch 21/500, Training Loss: 0.6160, Validation Loss: 1.2442, LR: 0.000050
2024-11-08 15:51:54,421 - INFO - Epoch 22/500, Batch 0/205, Loss: 0.6388
2024-11-08 15:52:01,140 - INFO - Epoch 22/500, Batch 10/205, Loss: 0.4870
2024-11-08 15:52:07,796 - INFO - Epoch 22/500, Batch 20/205, Loss: 0.5070
2024-11-08 15:52:14,640 - INFO - Epoch 22/500, Batch 30/205, Loss: 0.5601
2024-11-08 15:52:21,156 - INFO - Epoch 22/500, Batch 40/205, Loss: 0.7431
2024-11-08 15:52:27,890 - INFO - Epoch 22/500, Batch 50/205, Loss: 0.4141
2024-11-08 15:52:34,406 - INFO - Epoch 22/500, Batch 60/205, Loss: 0.5512
2024-11-08 15:52:41,187 - INFO - Epoch 22/500, Batch 70/205, Loss: 0.6276
2024-11-08 15:52:47,765 - INFO - Epoch 22/500, Batch 80/205, Loss: 0.6501
2024-11-08 15:52:54,406 - INFO - Epoch 22/500, Batch 90/205, Loss: 0.5797
2024-11-08 15:53:01,046 - INFO - Epoch 22/500, Batch 100/205, Loss: 0.7919
2024-11-08 15:53:07,671 - INFO - Epoch 22/500, Batch 110/205, Loss: 0.7581
2024-11-08 15:53:14,343 - INFO - Epoch 22/500, Batch 120/205, Loss: 0.5716
2024-11-08 15:53:20,946 - INFO - Epoch 22/500, Batch 130/205, Loss: 0.7320
2024-11-08 15:53:27,524 - INFO - Epoch 22/500, Batch 140/205, Loss: 0.5977
2024-11-08 15:53:34,149 - INFO - Epoch 22/500, Batch 150/205, Loss: 0.5181
2024-11-08 15:53:40,759 - INFO - Epoch 22/500, Batch 160/205, Loss: 0.6184
2024-11-08 15:53:47,493 - INFO - Epoch 22/500, Batch 170/205, Loss: 0.6402
2024-11-08 15:53:54,134 - INFO - Epoch 22/500, Batch 180/205, Loss: 0.5896
2024-11-08 15:54:00,634 - INFO - Epoch 22/500, Batch 190/205, Loss: 0.6903
2024-11-08 15:54:07,290 - INFO - Epoch 22/500, Batch 200/205, Loss: 0.5175
2024-11-08 15:54:22,134 - INFO - Epoch 22/500, Training Loss: 0.5934, Validation Loss: 1.2422, LR: 0.000050
2024-11-08 15:54:29,337 - INFO - Epoch 23/500, Batch 0/205, Loss: 0.5319
2024-11-08 15:54:35,962 - INFO - Epoch 23/500, Batch 10/205, Loss: 0.5446
2024-11-08 15:54:42,493 - INFO - Epoch 23/500, Batch 20/205, Loss: 0.4795
2024-11-08 15:54:49,134 - INFO - Epoch 23/500, Batch 30/205, Loss: 0.5225
2024-11-08 15:54:55,805 - INFO - Epoch 23/500, Batch 40/205, Loss: 0.5909
2024-11-08 15:55:02,290 - INFO - Epoch 23/500, Batch 50/205, Loss: 0.5716
2024-11-08 15:55:08,930 - INFO - Epoch 23/500, Batch 60/205, Loss: 0.6786
2024-11-08 15:55:15,680 - INFO - Epoch 23/500, Batch 70/205, Loss: 0.6911
2024-11-08 15:55:22,134 - INFO - Epoch 23/500, Batch 80/205, Loss: 0.7227
2024-11-08 15:55:28,837 - INFO - Epoch 23/500, Batch 90/205, Loss: 0.4629
2024-11-08 15:55:35,415 - INFO - Epoch 23/500, Batch 100/205, Loss: 0.5133
2024-11-08 15:55:41,868 - INFO - Epoch 23/500, Batch 110/205, Loss: 0.6592
2024-11-08 15:55:48,493 - INFO - Epoch 23/500, Batch 120/205, Loss: 0.4966
2024-11-08 15:55:55,024 - INFO - Epoch 23/500, Batch 130/205, Loss: 0.6421
2024-11-08 15:56:01,759 - INFO - Epoch 23/500, Batch 140/205, Loss: 0.5884
2024-11-08 15:56:08,227 - INFO - Epoch 23/500, Batch 150/205, Loss: 0.4231
2024-11-08 15:56:14,837 - INFO - Epoch 23/500, Batch 160/205, Loss: 0.5304
2024-11-08 15:56:21,399 - INFO - Epoch 23/500, Batch 170/205, Loss: 0.5502
2024-11-08 15:56:28,009 - INFO - Epoch 23/500, Batch 180/205, Loss: 0.6004
2024-11-08 15:56:34,634 - INFO - Epoch 23/500, Batch 190/205, Loss: 0.6746
2024-11-08 15:56:41,227 - INFO - Epoch 23/500, Batch 200/205, Loss: 0.3903
2024-11-08 15:56:56,227 - INFO - Epoch 23/500, Training Loss: 0.5708, Validation Loss: 1.3173, LR: 0.000050
2024-11-08 15:57:03,337 - INFO - Epoch 24/500, Batch 0/205, Loss: 0.6338
2024-11-08 15:57:10,024 - INFO - Epoch 24/500, Batch 10/205, Loss: 0.5388
2024-11-08 15:57:16,680 - INFO - Epoch 24/500, Batch 20/205, Loss: 0.4490
2024-11-08 15:57:24,403 - INFO - Epoch 24/500, Batch 30/205, Loss: 0.6676
2024-11-08 15:57:31,430 - INFO - Epoch 24/500, Batch 40/205, Loss: 0.4237
2024-11-08 15:57:37,977 - INFO - Epoch 24/500, Batch 50/205, Loss: 0.5000
2024-11-08 15:57:44,602 - INFO - Epoch 24/500, Batch 60/205, Loss: 0.5087
2024-11-08 15:57:51,320 - INFO - Epoch 24/500, Batch 70/205, Loss: 0.5916
2024-11-08 15:57:57,914 - INFO - Epoch 24/500, Batch 80/205, Loss: 0.4372
2024-11-08 15:58:04,570 - INFO - Epoch 24/500, Batch 90/205, Loss: 0.4634
2024-11-08 15:58:11,555 - INFO - Epoch 24/500, Batch 100/205, Loss: 0.4799
2024-11-08 15:58:18,399 - INFO - Epoch 24/500, Batch 110/205, Loss: 0.6257
2024-11-08 15:58:25,258 - INFO - Epoch 24/500, Batch 120/205, Loss: 0.4458
2024-11-08 15:58:31,914 - INFO - Epoch 24/500, Batch 130/205, Loss: 0.5206
2024-11-08 15:58:38,586 - INFO - Epoch 24/500, Batch 140/205, Loss: 0.4997
2024-11-08 15:58:45,258 - INFO - Epoch 24/500, Batch 150/205, Loss: 0.6006
2024-11-08 15:58:51,883 - INFO - Epoch 24/500, Batch 160/205, Loss: 0.5627
2024-11-08 15:58:58,383 - INFO - Epoch 24/500, Batch 170/205, Loss: 0.4856
2024-11-08 15:59:04,992 - INFO - Epoch 24/500, Batch 180/205, Loss: 0.5805
2024-11-08 15:59:11,586 - INFO - Epoch 24/500, Batch 190/205, Loss: 0.7367
2024-11-08 15:59:18,320 - INFO - Epoch 24/500, Batch 200/205, Loss: 0.4135
2024-11-08 15:59:33,195 - INFO - Epoch 24/500, Training Loss: 0.5484, Validation Loss: 1.2929, LR: 0.000050
2024-11-08 15:59:33,195 - INFO - Reached early stopping criteria
2024-11-08 15:59:33,195 - INFO - Training completed successfully!
2024-11-08 15:59:49,570 - INFO - Final evaluation metrics:
2024-11-08 15:59:49,570 - INFO - Precision: 0.613
2024-11-08 15:59:49,570 - INFO - Recall: 0.752
2024-11-08 15:59:49,570 - INFO - F1: 0.675
